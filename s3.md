# Amazon S3 (Simple Storage Service)

Amazon S3 (Simple Storage Service) is a scalable object storage service offered by AWS that allows you to store and retrieve data from anywhere on the web. It is designed to provide high durability, availability, and scalability for storing a wide variety of data, including images, videos, documents, backups, and logs.
<div style="text-align:center">
![S3](./images/s3.png)
</div>
## Key Concepts:
1. **Buckets:** A bucket is a container for objects stored in Amazon S3. You can create multiple buckets to organize and manage your data.
2. **Objects:** Objects are the fundamental entities stored in Amazon S3. An object can be any file or data, along with metadata, stored as a key-value pair.
3. **Regions:** Amazon S3 is globally distributed across multiple geographical regions. You can choose the region where you want to create your buckets to optimize latency and compliance requirements.
4. **Storage Classes:** Amazon S3 offers different storage classes, including Standard, Standard-IA (Infrequent Access), One Zone-IA, Intelligent-Tiering, Glacier, and Glacier Deep Archive, each designed for specific use cases based on data access frequency and durability requirements.
5. **Lifecycle Policies:** You can define lifecycle policies to automatically transition objects between different storage classes or delete them after a specified period.

## Features:
- **Durability and Availability:** Amazon S3 is designed to provide 99.999999999% (11 nines) durability and 99.99% availability for your data.
- **Scalability:** S3 can scale to accommodate any amount of data, from a few gigabytes to petabytes or more, without any upfront provisioning.
- **Security:** S3 offers various security features, including encryption at rest and in transit, access control via IAM policies and bucket policies, and integration with AWS Key Management Service (KMS) for managing encryption keys.
- **Versioning:** You can enable versioning on your S3 buckets to preserve, retrieve, and restore every version of every object stored in the bucket.
- **Cross-Region Replication:** You can replicate objects across different AWS regions for disaster recovery, compliance, and low-latency access.
- **Event Notifications:** S3 supports event notifications that can trigger AWS Lambda functions, SNS topics, or SQS queues in response to object creation, deletion, or restore events.

## Use Cases:
- **Static Website Hosting:** Amazon S3 can host static websites by serving HTML, CSS, JavaScript, and other web assets directly from buckets.
- **Data Backup and Archiving:** S3 is commonly used for data backup and long-term archival storage due to its durability and cost-effectiveness.
- **Content Distribution:** S3 integrates with Amazon CloudFront, AWS's content delivery network (CDN), to distribute content globally with low latency and high transfer speeds.
- **Data Lakes:** S3 serves as a foundational component for building data lakes, allowing organizations to store and analyze large volumes of structured and unstructured data at scale.

# Steps to Create a Bucket in Amazon S3

1. **Sign in to the AWS Management Console:**
   Open a web browser and navigate to the [AWS Management Console](https://aws.amazon.com/console/). Sign in to your AWS account using your credentials.

2. **Navigate to Amazon S3:**
   Once logged in, search for "S3" in the AWS Management Console search bar, and click on the "Amazon S3" service in the search results. Alternatively, you can find Amazon S3 under the "Storage" category in the AWS Management Console.

3. **Create a New Bucket:**
   - Click on the "Create bucket" button to start the bucket creation process.
   - Enter a unique name for your bucket in the "Bucket name" field. Bucket names must be globally unique across all existing bucket names in Amazon S3.
   - Choose the AWS region where you want to create the bucket. Select the region closest to your users to minimize latency.
   - Click on the "Create" button to create the bucket.

4. **Configure Bucket Properties (Optional):**
   - After creating the bucket, you can configure optional properties such as versioning, server access logging, default encryption, and tags. These configurations can be adjusted later if needed.

5. **Set Bucket Permissions (Optional):**
   - By default, newly created buckets are private and can only be accessed by the bucket owner. If you want to grant public access or specific permissions to other AWS accounts or IAM users, you can configure bucket policies and access control lists (ACLs) in the "Permissions" tab.

6. **Confirmation:**
   - Once you have configured the bucket properties and permissions, click on the "Create bucket" button to confirm and create the bucket.
   - You will see a confirmation message indicating that the bucket has been successfully created.

7. **Access Your Bucket:**
   - After the bucket is created, you can start uploading objects (files) to the bucket using the Amazon S3 console, AWS CLI, SDKs, or third-party tools.

8. **Explore Additional Features:**
   - Explore additional features of Amazon S3 such as lifecycle policies, cross-region replication, event notifications, and object metadata to further customize and manage your bucket and its contents.

# Create Bucket, Set Public Access Block, and Upload File Using AWS CLI

## Create Bucket:
```bash
aws s3api create-bucket --bucket my-example-bucket --region us-west-2
```
## Set Public Access Block:
```bash
aws s3api put-public-access-block --bucket my-example-bucket --public-access-block-configuration "BlockPublicAcls=true,IgnorePublicAcls=true,BlockPublicPolicy=true,RestrictPublicBuckets=true"
```
## Upload file:
```bash
aws s3api put-object --bucket my-example-bucket --content-type image/jpeg --key myImage.jpg --body /mnt/c/aws/myImage.jpg
```
## Allow Public Read
```bash
aws s3api delete-public-access-block --bucket my-example-bucket

aws s3api put-object-acl --bucket my-example-bucket --key myImage.jpg --acl public-read
```
## Delete File
```bash
aws s3api delete-object --bucket my-example-bucket --key myImage.jpg
```
## Delete Bucket
```bash
aws s3api delete-bucket --bucket my-example-bucket --region us-west-2
```

# Security and Permissions on an Amazon S3 Bucket

Amazon S3 provides several mechanisms to control access to your buckets and objects, ensuring that only authorized users or applications can interact with your data. Here are some key aspects of security and permissions in Amazon S3:

## Bucket Policies:
- **Bucket-Level Access Control:** You can define bucket policies to control access to the entire bucket based on various conditions, including IP address, VPC endpoint, AWS account, or IAM identity.
- **JSON-based Policies:** Bucket policies are JSON documents that specify who can access the bucket and what actions they can perform. Policies can be attached to individual buckets to define granular access controls.
- **Cross-Account Access:** Bucket policies can grant access to resources in other AWS accounts, enabling cross-account sharing of objects.
- **Evaluation:** Bucket policies are evaluated before any other access control mechanisms, such as IAM policies or ACLs. They provide a centralized way to manage access control for all objects within the bucket.
- **Example:**
```json
{
    "Version": "2012-10-17",
    "Id": "ExamplePolicy01",
    "Statement": [
        {
            "Sid": "ExampleStatement01",
            "Effect": "Allow",
            "Principal": {
                "AWS": "arn:aws:iam::123456789012:user/Dave"
            },
            "Action": [
                "s3:GetObject",
                "s3:GetBucketLocation",
                "s3:ListBucket"
            ],
            "Resource": [
                "arn:aws:s3:::awsexamplebucket1/*",
                "arn:aws:s3:::awsexamplebucket1"
            ]
        }
    ]
}

//cli

aws s3api put-bucket-policy --bucket my-example-bucket --policy file://policy.json
```

## Access Control Lists (ACLs):
- **Object-Level Access Control:** ACLs are another way to control access to individual objects within a bucket. ACLs can grant read, write, and delete permissions to specific AWS accounts or predefined groups.
- **Fine-Grained Control:** ACLs allow you to specify permissions for individual AWS accounts, predefined groups (e.g., authenticated users, all users), or specific email addresses.

## IAM Policies:
- **User-Level Access Control:** IAM (Identity and Access Management) policies are used to manage access permissions for IAM users and roles. IAM policies can grant access to specific S3 buckets and objects based on various conditions and actions.
- **Granular Permissions:** IAM policies support granular permissions, allowing you to specify which API actions (e.g., s3:GetObject, s3:PutObject) are allowed or denied for specific resources.
- **Temporary Access:** IAM roles can be used to grant temporary access to S3 resources for applications running on EC2 instances, Lambda functions, or other AWS services.

## Pre-Signed URLs:
- **Temporary Access Links:** Pre-signed URLs allow you to generate temporary URLs that grant access to specific objects in your bucket for a limited time period. Pre-signed URLs are often used for providing temporary access to private objects without requiring AWS credentials.

## Default Encryption:
- **Data Encryption:** Amazon S3 offers default encryption options to encrypt data at rest to protect against unauthorized access. You can enable default encryption for a bucket to automatically encrypt all objects stored in the bucket using server-side encryption (SSE) with Amazon S3-managed keys (SSE-S3) or customer-managed keys (SSE-C).

## Access Logging:
- **Audit Trail:** Amazon S3 provides access logging features that allow you to track requests made to your bucket and objects. Access logs capture details such as the requester's IP address, HTTP method, and response status, providing visibility into access patterns and potential security threats.

## Block Public Access:
- **Restrict Public Access:** Amazon S3 offers settings to block public access to your buckets and objects by default. You can enable block public access settings at the account level or individual bucket level to prevent accidental exposure of sensitive data to the public internet.

# Amazon S3 Storage Classes by Category

Amazon S3 offers a variety of storage classes designed to meet different performance, durability, and cost requirements. These storage classes are categorized into three main categories: Standard, Infrequent Access, and Glacier.

## Standard Storage Classes:
- **S3 Standard**: The default storage class designed for frequently accessed data with high availability, durability, and low latency. Ideal for frequently accessed data such as active workloads, multimedia content, and data analytics. $0.023 GB/Month

- **S3 Intelligent-Tiering**: A storage class designed for data with unknown or changing access patterns. Automatically moves data between two access tiers: frequent access and infrequent access, optimizing costs based on access patterns. object monitoring cost $0.00025 per 1000 objects

## Infrequent Access Storage Classes:
- **S3 Standard-IA (Infrequent Access)**: Designed for data that is accessed less frequently but requires rapid access when needed. Offers the same availability and durability as S3 Standard but with lower storage costs and higher retrieval fees. $0.0125 GB/Month - min storage duration 30 days - >= 3 AZ - 99.9% - retrieval $0.01 GB

- **S3 One Zone-IA**: Similar to S3 Standard-IA but stores data in a single Availability Zone, offering lower storage costs than S3 Standard-IA but with slightly less durability.$0.01 GB/Month - min storage duration 30 days - 1 AZ - 99.5% - retrieval $0.01 GB

## Glacier Storage Classes:
- **Amazon S3 Glacier**: A low-cost storage class designed for long-term data archiving with retrieval times ranging from minutes to hours. Suitable for data archiving, compliance, and regulatory requirements where access times are less critical. $0.004 GB/Month - min storage duration 90 days - $0.03 GB retrieval - ms access time

- **Amazon S3 Glacier Flexible Retrieval**: A storage class designed to provide the flexibility to choose between three retrieval options: Expedited, Standard, and Bulk. Each retrieval option has different pricing and availability characteristics, allowing you to tailor retrieval times and costs based on your specific needs. $0.0036 GB/Month - min storage duration 90 days - $0.01 to $0.03 GB retrieval - minutes to hours access time

- **Amazon S3 Glacier Deep Archive**: The lowest-cost storage class designed for long-term data retention and archiving with retrieval times ranging from hours to days. Ideal for data that is accessed rarely and has strict compliance and regulatory requirements. $0.00099 GB/Month - min storage duration 180 days - $0.02 GB retrieval - hours access time

## Other Storage Classes:
- **S3 Outposts**: A storage class designed for data stored on AWS Outposts, offering the same features and performance as S3 Standard but within the customer's data center.

- **S3 Object Lock**: A feature that allows you to apply retention periods and legal holds to objects, ensuring they remain immutable and protected against deletion or modification for a specified duration.

These storage classes provide flexibility in managing data based on access patterns, performance requirements, and cost considerations, allowing you to optimize storage costs while meeting your specific needs.


# Amazon S3 Lifecycle Policies

Amazon S3 lifecycle policies allow you to define rules to automatically manage the lifecycle of your objects stored in S3 buckets. With lifecycle policies, you can define actions such as transitioning objects to different storage classes, deleting objects after a specified period, or archiving objects to Amazon S3 Glacier or Glacier Deep Archive.

## Benefits of S3 Lifecycle Policies:
- **Cost Optimization**: Automatically move objects to less expensive storage classes as they age or delete them when they're no longer needed to optimize storage costs.
- **Data Management**: Simplify data management by automatically managing the lifecycle of objects without manual intervention.
- **Compliance and Retention**: Ensure compliance with regulatory requirements by automatically archiving or deleting objects based on retention policies.

## Components of S3 Lifecycle Policies:
- **Rules**: Define rules to specify the conditions and actions for managing the lifecycle of objects.
- **Transitions**: Specify when to transition objects to a different storage class based on their age or other criteria.
- **Expiration**: Define expiration actions to automatically delete objects after a specified period.

## Example Lifecycle Policy:
```json
{
    "Rules": [
        {
            "ID": "MoveToGlacier",
            "Status": "Enabled",
            "Filter": {
                "Prefix": "logs/"
            },
            "Transitions": [
                {
                    "Days": 30,
                    "StorageClass": "GLACIER"
                },
                {
                    "Days": 365,
                    "StorageClass": "DEEP_ARCHIVE"
                }
            ],
            "Expiration": {
                "Days": 3650
            }
        }
    ]
}
```
## In this example:
- The rule with the ID "MoveToGlacier" is enabled and applies to objects with the prefix "logs/".
- Objects matching the filter are transitioned to the GLACIER storage class after 30 days and to the DEEP_ARCHIVE storage class after 365 days.
- Objects are automatically deleted after 3650 days (10 years)

## Notes:
- You can define multiple rules in a lifecycle policy to apply different lifecycle actions to different sets of objects.
- Lifecycle policies can be applied at the bucket level and are automatically applied to all objects within the bucket that match the rule criteria.

[Back to mian](readme.md)
